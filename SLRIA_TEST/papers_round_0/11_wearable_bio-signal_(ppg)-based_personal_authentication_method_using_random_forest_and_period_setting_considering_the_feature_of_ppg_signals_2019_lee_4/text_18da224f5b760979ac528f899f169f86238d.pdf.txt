 
 
Wearable Bio-Signal(PPG)-Based Personal Authentication 
Method Using Random Forest and Period Setting 
Considering the Feature of PPG Signals 
 
 
 
 
 
 
 
* Corresponding author. Tel.: +82-42-860-6559; email: pmah@etri.re.kr 
Manuscript submitted February 13, 2019; accepted April 15, 2019.  
doi: 10.17706/jcp.14.4.283-294
 
 
Abstract: A study regarding personal authentication based on PPG has been conducted using the Random 
Forest algorithm. In order to ensure correct authentication, data features must be consistent. This 
consistency is provided through the normalization of the PPG signal using maximum-minimum 
normalization and spline interpolation. The threshold is set by using normalized data and the highest value 
among the points above the threshold is set as the peak of the period. After establishing candidates of valley 
with values below the threshold, a shifted period is calculated by designating the last valley next to the 
following peak to the valley of the period. In order to reduce errors in the one period PPG data, the data is 
averaged after overlapping. A discrete cosine transform (DCT) is used to extract features from the 
preprocessed data. Thus, the extracted features are used as the input variables for machine learning 
techniques such as Decision Tree, KNN, Random Forest. The accuracy of these algorithms is 93%, 98%, and 
99% respectively.  
 
Key words: Wearable, bio-signal, biometric authentication, machine learning, photoplethysmography 
(PPG). 
 
 
1. Introduction 
The development of information technology over the past few decades has brought about technological 
convenience, but the number of issues related to personal information, privacy invasion, and hacking is 
increasing. In order to solve this problem, password, PIN number, certificate, and biometric methods are 
used [1]. Unlike the other existing authentication methods, biometrics can be authenticated without the 
need to carry a certificate, they do not rely on memory, and they are difficult to duplicate. 
Today’s biometric authentication methods include fingerprint, iris, face recognition, electrocardiogram 
(ECG), and photo-plethysmography (PPG). The most prevalent among these methods is fingerprint 
recognition. However, in the case of this method, it can be difficult to confirm the identity of a fingerprint 
when the fingerprint is damaged. Moreover, there is the possibility of fingerprint falsification, as a 
fingerprint pattern can be reproduced using latex. 
In the cases of ECG and PPG, reproduction is impossible since they rely on a bio-signal generated by the 
heartbeat. However, ECG requires at least two points of connection with the body, and there is the 
Journal of Computers
283
Volume 14, Number 4, April 2019
Sun-Woo Lee1*, Duk-Kyun Woo2, Yong-Ki Son3, Pyeong-Soo Mah2
1Department of ICT, University of Science and Technology (UST) , Daejeon, Rep. of Korea. 
2Embedded System Software Research Group, Electronics and Telecommunications Research Institute
(ETRI).
3Wearable Computing Research Institute, Electronics and Telecommunications Research Institute (ETRI).
 
 
drawback of contamination problems that may occur due to issues related to electrode attachment. 
In the case of PPG, the PPG sensor is attached to many wearable products such as many wearable 
watches and bands. Thus, it allows ease of measurement and there is little resistance to the measurement 
process. As an example, it is possible to provide increased convenience to people automatically 
opening/closing the door of a car by authenticating the user using a wearable band rather than a smart key. 
The main problem associated with PPG is that the shape of the PPG signal forms a smooth curve and there 
are no visible feature points, leading to difficulties in selecting feature points and feature extraction 
sections. Therefore, it is necessary to find a method that addresses this issue. Another complication relates 
to the tendency of the PPG signal that can be affected by motion noise. 
Existing PPG-based personal authentication methods can be classified into two types: Fiducial (F) and 
Non-Fiducial (NF). The Fiducial method is an authentication approach that relies on finding the features of 
the signal in the time domain of the PPG signal. This process of finding the features in the time domain is 
conducted using two methods: using the PPG signal and Acceleration PPG (APG), typical signals of which 
are shown in Fig. 1. There have been several studies on the former approach and Y. Gu et al. introduced a 
personal authentication algorithm that uses the PPG signal [2], [3]. As a result, Y. Gu et al. obtained a 94% 
authentication result through 17 PPG data signal features of the peak, time interval, upward slope, and 
downward slope [3]. The simplicity of the signal adds a disadvantage to the use of PPG signals since it is 
difficult to analyze and detect the change of phases. In order to compensate for this, previous studies have 
been conducted second derivatives of PPG signal in order to obtain features using APG signals [4]-[6]. 
 
 
(a) PPG signal 
 
 
 
(b) APG signal 
Fig. 1. Comparison of PPG and APG signal.  
 
Jaafar et al. [5] used features extracted from APG signals in order to provide a 97.5% result for personal 
authentication using a Bayes network and a K nearest neighbor classification technique. 
Although most studies have been conducted using the fiducial method, Karimian et al. [7] obtained better 
results with a non-fiducial method using ECG data. However, in the case of one non-fiducial method, there is 
a difficulty in interpreting results obtained using data extracted using Discrete wavelet transforms (DWT) 
because it is expressed in the form of complex numbers [8]. 
Journal of Computers
284
Volume 14, Number 4, April 2019
 
 
2. Proposed PPG-Based Biometric Authentication 
In this study, we propose a biometric authentication method using PPG signals with improved accuracy 
by complementing the disadvantages of existing PPG approaches due to the smooth shape of the PPG signal 
and the  difficulties related to feature point and section selection. In order to improve accuracy, data 
features must be consistently preprocessed. To ensure data consistency, the peak is found in the PPG signal 
data, period normalization is then applied using the spline method, and the average is applied to the data 
that are overlapped three times. Discrete cosine transform (DCT) [9] is used through an extracting feature 
As shown in Fig. 2, the proposed personal authentication method consists of several steps: preprocessing, 
feature extraction, identity verification, and conformation of results. 
 
 
Fig. 2. Personal authentication procedure. 
 
2.1. Overview of Data Preprocessing Method 
The PPG signal is periodic, as an electrical signal that is affected by heartbeat. Some amount of DC 
component is to be removed from the PPG signal using Equation 1 to obtain an effective threshold. The 
closer the alpha value is set to 1, the more DC component is removed. In this study, the DC component was 
removed by setting the alpha value to 0.95 recommended in [11].  
 
y(t) : output of the filter 
x(t) : current input 
w(t) : intermediate value 
α : the response constant of the filter 
 ( )   ( )     (   ) 
 ( )   ( )   (   ) 
(1)
 
  
 
Fig. 3. Data preprocessing method.  
 
Since the amplitude of each PPG signal is different for each individual, the magnitude of the amplitude of 
the PPG signal is normalized between 0 and 1, and maximum-minimum normalization relation given in 
Equation 2 is applied.  
Journal of Computers
285
Volume 14, Number 4, April 2019
method and the Random Forest [10] machine learning method is applied as the personal authentication 
method. 
 
 
              [ ]   [ ]      
         
 
    (2) 
 
Using the normalized data, threshold is set by calculating an average using average filter which is shown 
in equation 3. 
 ̅   
 
    ̅     
    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(3)
 
 
The normalized data and threshold are used for input of peak and one period setting method block. In 
order to reduce signal error, the data are interpolated and the average was set by preprocessing as shown 
in Fig. 3. 
2.2. Peak and Period Set Method 
Finding peak points in the PPG signal is a preliminary task to find out the periods. There are several 
methods to extract the peak, including utilizing zero-crossing method [12] and differentiating the PPG 
signal to set the largest change point as the peak [12]. In the study, the zero-crossing method is used to find 
out peaks in the PPG signal and the period is set by considering the peak-peak time. The threshold is 
calculated using the average filter shown in Equation 3 to extract the peak. Equation 3 improves the 
efficiency of calculation by applying the expression that uses only the previous mean result and the 
additional data instead of the batch expression that collects and calculates all the data at once.  
 
 
Fig. 4. period set method and valley set among the nominees. 
 
As shown in Fig. 4, the Peak (i) is set as the component with the largest value above the threshold and 
peak(i+1) is calculated by considering the peak-peak time. In order to obtain the characteristics of signals 
of subjects in one cycle of the PPG signal, the period is shifted to include components such as the systolic, 
diastolic peak and dicrotic notch. As a method to shift the period, the mean distance from the peak to valley 
is calculated and half of the mean distance is applied to shift. In the PPG signal, characteristics of these 
components are unique in each subject since these are produced when the heart is contracts and relaxes. In 
order to establish the period of signals which are affected by the contraction and relaxation of the heart, the 
setting point of the period is shifted to the left side of the peak. The smallest points which are below the 
threshold is set to the valley of the period. However, there can be a problem in case that there are many 
non-consecutive candidate valleys as shown in Fig. 4. When the points that do not exceed the base point 
occur in more than two spots the last valley points that is the nearest valley to the next Peak, Peak(i+1) is 
Journal of Computers
286
Volume 14, Number 4, April 2019
 
 
chosen at the valley of the period. The block diagram of the above peak and period set method is shown in 
Fig. 5.  
 
 
Fig. 5. A method of periodic extraction considering characteristics of PPG signal. 
 
The PPG signal peak is extracted by considering periodicity and threshold. Unlike the approach employed 
in previous studies [13], the spline interpolation method is used in order to maintain the features of the 
PPG signal, instead of separating the fixed period length. It reduce the differences in the distance of one 
cycle and maintain data features. 
The method used to set one period in the PPG data is given in Fig. 6. The average Peak-Valley distance is 
shifted in order to utilize the pulse features from Peak to Valley, instead of extracting features from signals 
between Shift_Peak Valley(SV)s. Thus, the data are preprocessed in order to express electronic features 
related to heartbeats in the PPG signals, setting up one cycle of the shifted SV. 
 
 
Fig. 6. Process of setting up one cycle of the PPG data.  
 
2.3. Error Reduction Method 
When averages are applied using an ensemble technique in order to extract individual features [14], 
issues related to machine learning training process may be introduced due to a reduction in the amount of 
data. As shown in Fig. 7, the data set is constructed here by overlapping three SV sections of one period in 
the PPG data, maximizing the total amount of data. 
 
 
                           
                           
…… 
                               
Fig. 7. Data averaging method.  
Journal of Computers
287
Volume 14, Number 4, April 2019
 
 
The SV interval is set up for one cycle and a specific feature is extracted using DCT for that cycle, and the 
extracted data contained in the 4-20Hz range is used as that feature. In addition, if this feature is extracted 
using the DCT without using the overlapped average, errors will occur and reduce the accuracy of the 
personal authentication method. Overlapped averages are used in order to reduce error. A decrease in the 
difference between each cycle amplitude can be seen in Fig. 9, where the proposed overlapped average 
approach is used, compared to Fig. 8, where the original data is used. 
 
 
Fig. 8. DCT without overlap averaging. 
 
 
Fig. 9. DCT with overlap averaging.  
 
2.4. Feature Extraction Using Discrete Cosine Transform 
Since the individual features of the PPG data are located at low frequency, DCT is performed in order to 
extract low frequency features. In the case where using DWT produced results containing complex 
numbers [8], the necessary calculations are too complicated  to be processed using wearable device. On 
the other hand, computational complexity is reduced by using DCT, which is a real-valued transformation 
method. 
In previous studies [15], DCT was used as a feature extraction technique for ECG data which, like PPG, is 
one of the signals generated by heartbeat. Similar to the ECG data case, here the frequency components 
were concentrated at low frequencies in the PPG data. Here, DCT was successfully employed in extracting 
low-frequency features of the PPG data. 
Journal of Computers
288
Volume 14, Number 4, April 2019
 
 
2.5. Personal Authentication Using Random Forest 
In order to conduct personal authentication, DCT related to the extracted data are used as input variables 
for the Random Forest process. The most important goal of the individual authentication process is to 
improve accuracy. Random Forest is better suited to personal recognition than other machine learning 
algorithms such as KNN [16] and SVM [16], because it is more accurate due to the capacity to change the 
number of standard trees that need to be identified. 
The Random Forest machine learning algorithm was proposed by L. Reiman [10]. Fig. 10 shows the 
classification method of Random Forest. Random Forest is characterized by voting using Decision Trees 
[16]. 
 
 
Fig. 10. Random forest classification method.  
 
3. Experiment and Results 
3.1. Experimental Environment 
Experiments in this study were performed using the MATLAB and Python computer codes. 
 
 
Fig. 11. PPG data processing environment.  
 
TDME2013_PPG_Benchmark_R3 [17], [18] was followed, which is widely used for algorithm verification. 
The benchmark consists of 42 people, with a 300Hz sampling rate and 8 minutes of data per person. Data 
were reconstructed using 100 periodic data within the 8-minute data time. 
Table 1 shows the results of applying the Decision Tree (DT), KNN, and Random Forest (RF) machine 
learning techniques in order to reduce errors using both the proposed overlapped averages method and the 
original data without overlapped averages. 
Using the proposed overlap average method, the accuracy of all machine learning techniques can be 
Journal of Computers
289
Volume 14, Number 4, April 2019
 
 
improved.  
 
Table 1. Existing and Proposed Techniques 
AVG 
Decision 
Tree 
KNN 
Random 
Forest 
Original data 
80% 
92% 
92% 
After applying 
overlap 
average 
89% 
94% 
96% 
Period and DCT 
value overlap 
average 
93% 
98% 
99% 
 
3.2. Comparison of Accuracy Based on Amount of Data 
To use PPG signals for authentication in real environment, it should not take too long and maintain 
accuracy. If it takes a long time, user may feel uncomfortable. Therefore, we experimented to see how 
accuracy and time vary as we change the number of pulse. Table 2 shows the accuracy of each machine 
learning method using 10, 30, 50, and 100 peak periods. The accuracy of individual authentication varies 
according to the amount of data that is presented for machine learning. 
 
Table 2. Existing and Proposed Preprocessing Techniques 
Periods 
Decision 
Tree 
KNN 
Random 
Forest 
10 
87% 
96% 
98% 
30 
91% 
98% 
99% 
50 
94% 
98% 
99% 
100 
93% 
98% 
99% 
 
Decision Tree showed the greatest change in accuracy according to the amount of data. In the case of 
Random Forest, performance was consistent above 30 periods of data. Also, the larger periods are used, the 
faster the result of experiment, with the same accuracy. 
3.3. Setting Optimal Parameters for Machine Learning 
In order to extract the features of each pulse in the data, DCT was performed to obtain DCT coefficients. 
Pulses were extracted within the range from 4 to 20 Hz, as the features required to distinguish individuals 
are distributed at frequencies below 20 Hz. 
 
 
Fig. 12. Decision tree experiment results.  
Journal of Computers
290
Volume 14, Number 4, April 2019
 
 
 
 
Fig. 13. KNN experiment results.  
 
 
Fig. 14. Random forest experiment results.  
 
Features were extracted from the DCT of PPG data and the performances were verified using DT, KNN, 
and RF techniques. In order to compare the performance of each machine learning algorithm, the accuracy 
of the algorithm is measured by increasing the parameters of the algorithm. The results for each machine 
learning algorithm are shown in Fig. 12, 13, and 14. 
In the case of the DT method, the optimal number of trees is determined by specifying the number of 
optimal trees, the number of neighbor’s K is specified for KNN, and the number of trees is chosen for the 
Random Forest method. 
For the Decision Tree method, the optimal depth parameter was chosen at a tree depth of 21, after which 
there is no further increase in accuracy. In the case of KNN, the model is simple and the accuracy is lowered 
as K increases. In the case of the Random Forest method, the optimal parameters were obtained using 66 
trees, after which the results were stable and no further increase in accuracy is obtained. 
Following these tests, the DT experiment was carried out using a depth parameter of 19, yielding an 
accuracy result of 93%. In the case of KNN, the accuracy result was 93% at K = 2. In the case of Random 
Forest, the accuracy was 99% when using 66 trees. The proposed authentication method may be compared 
with existing authentication methods that employ PPG data. 
In the case of Gu et al. [2], [3], which describes the use of PPG signals in the literature for the first time, 
four features were extracted from the PPG signal, experiments were performed on 17 individuals, yielding 
an accuracy result of 94%. However, more research is needed to investigate how to use a small amount of 
data in a real environment, since it may be difficult to extract features in case PPG signals are smooth. 
In order to solve this problem, Sammik [4] and Jaagar [5] used APG signals in experiments with 15 and 
Journal of Computers
291
Volume 14, Number 4, April 2019
 
 
10 people, respectively, using the Fiducial method, and obtained accuracy results of 100% and 97.5%, 
respectively. However, since these data sets were small, further research is required in a real environment. 
In addition, the fiducial method using APG signals can be subject to issues related to the features such as the 
Dicrotic notch (see Fig. 15 c, d), which cannot be properly extracted from APG data when the inflection 
point is smooth. 
 
 
Fig. 15. Feature points of APG data.  
 
However, the proposed method provides lower errors than the APG feature extraction method because 
our proposed method uses only the peak and valley in the PPG signal is used. 
In the case of the Non-Fiducial method, Karimian [8] obtained a result of 100% for individual 
authentication, although the use of DWT as a feature extractor may mean that the calculations are too 
complicated for a wearable device environment. 
The proposed method, however, uses DCT in order to simplify the calculation process in a wearable 
device environment, and when using Random Forest, 42 people were authenticated with an accuracy of 
99%. Therefore, a combination of Random Forest and DCT is suitable for use with wearable devices. 
 
Table 3. Comparison of Authentication Method Using PPG Data 
Study 
Feature 
(Subject) 
Classification 
Method 
Accuracy 
Gu 
et al[2][3] 
Fiducial 
(17) 
Euclidean 
Distance [2] 
Fuzzy[3] 
94% 
Chakrabory 
et al[4] 
Fiducial 
(15) 
LDA 
100% 
Jaagar 
et al[5] 
Fiducial 
(10) 
Bayes Network 
97.5% 
Kavsoglu 
et al[6] 
Fiducial 
(40) 
KNN 
94.4% 
Karimian 
et al[8] 
Non-Fiducial 
(42) 
GA + ANN 
100% 
Proposed 
Non- Fiducial 
(42) 
Random Forest 
99% 
 
Table 3 summarizes results obtained using several authentication methods by various researchers, 
including the Non-Fiducial method using PPG and APG and other existing fiducial methods. 
4. Conclusion and Future Work 
In the proposed individual authentication method, machine learning approach was used together with 
spline interpolation and overlap averaging. The accuracies of decision tree, KNN, and Random Forest were 
93%, 98%, and 99%, respectively. 
Journal of Computers
292
Volume 14, Number 4, April 2019
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Journal of Computers
293
Volume 14, Number 4, April 2019
 
 
In the case of personal authentication using PPG data, the accuracy of personal authentication is affected 
by the method of preprocessing the data. A shifted period can be controlled by selecting the last candidate 
valley as the valley of the period, even though the size of PPG signal. Periodic normalization is performed 
using spline interpolation and data is preprocessed using maximum-minimum normalization. DCT is 
employed in order to reduce computational complexity and to take advantage of the convergence of signals 
with features that distinguish a person at low frequency in the PPG signal. As a result of applying machine 
learning approach with extracted features, the best performance of 99% was provided by the Random 
Forest method.  
However, at least 66 trees are needed during the training process, which causes issues related to 
computational speed. The advantage of proposed method, on the other hand, is that it may be applied to 
wearable bands that are always worn, as automobile key alternatives that can authenticate users and allow 
the automatic opening and closing of doors. 
In the future, it is necessary to apply this approach to much larger sets of individuals and examine the 
resulting data and identification accuracy. Another important factor will be to study the robustness of this 
wearable technology with respect to noise, which can be applied in an embedded environment. 
Acknowledgment 
This work was supported by Korea Evaluation Institute of Industrial Technology (KEIT) grant funded by 
the Korea government (MOTIE) (No.10065738, Development of wearable development toolkit for various 
wearable application services).  
References 
[1] Korea Institute of Science and Technology information (KISTI) MARKET REPORT, 48, 2016.  
[2] Gu, Y. Y., Zhang, Y., & Zhang, Y. T. (2003). A novel biometric approach in human verification by 
photoplethysmographic signals. Proceedings of 4th International IEEE EMBS Special Topic Conference 
on Information Technology Applications in Biomedicine (pp. 13-14).  
[3] Gu, Y. Y., & Zhang, Y. T. (2003). Photoplethysmographic authentication through fuzzy logic. Proceedings 
of IEEE EMBS Asian-Pacific Conference on Biomedical Engineering (pp. 136-137).  
[4] Chakraborty, S., & Pal, S. (2016). Photoplethysmogram signal based biometric recognition using linear 
discriminant classifier. Proceedings of 2016 2nd International Conference on Control, Instrumentation, 
Energy & Communication (CIEC) (pp. 183-187).  
[5] Jaafar, N. A. L., Sidek, K. A., & Azam, S. N. A. M. (2015). Acceleration plethysmogram based biometric 
identification. Proceedings of 2015 International Conference on BioSignal Analysis, Processing and 
Systems (ICBAPS) (pp. 16-21).  
[6] Kavsaoğlu, A. R., Polat, K., & Bozkurt, M. R. (2014). A novel feature ranking algorithm for biometric 
recognition with PPG signals. Computers in Biology and Medicine, 49, 1-14. 
[7] Karimian, N., Guo, Z., Tehranipoor, M., & Forte, D. (2017). Highly reliable key generation from 
electrocardiogram (ecg). IEEE Transactions on Biomedical Engineering, 64(6), 1400-1411. 
[8] Karimian, N., Guo, Z., Tehranipoor, M., & Forte, D. (2017). Human recognition from 
photoplethysmography (ppg) based on non-fiducial features. Proceedings of 2017 IEEE International 
Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 4636-4640).  
[9] Ahmed, N., Natarajan, T., & Rao, K. R. (1974). Discrete cosine transform. IEEE Transactions on 
Computers, 100(1), 90-93.  
[10] Chen, C., Liaw, A., & Breiman, L. (2004). Using random forest to learn imbalanced data. University of 
California, Berkeley, 110, 1-12.  
[11] Implementing 
pulse 
oximeter 
using 
MAX30100. 
Retrieved 
from 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Journal of Computers
294
Volume 14, Number 4, April 2019
 
 
https://morf.lv/implementing-pulse-oximeter-using-max30100 
[12] Sarkar, A., Abbott, A. L., & Doerzaph, Z. (2016). Biometric authentication using photoplethysmography 
signals. Proceedings of 2016 IEEE 8th International Conference on Biometrics Theory, Applications and 
Systems (BTAS) (pp. 1-7).  
[13] Spachos, P., Gao, J., & Hatzinakos, D. (2011). Feasibility study of photoplethysmographic signals for 
biometric identification. Proceedings of 2011 17th International Conference on Digital Signal Processing 
(DSP) (pp. 1-5).  
[14] Choudhary, T., & Manikandan, M. S. (2016). Robust photoplethysmographic (PPG) based biometric 
authentication for wireless body area networks and m-health applications. Proceedings of 2016 Twenty 
Second National Conference on Communication (NCC) (pp. 1-6).  
[15] Jeong, K. K., Kang, B. L., & Sang, G. H.(2017). ECG-based biometric authenticaion using random forest. 
Journal of the Institutue of Eletronics and Information Engineers, 54(6), 100-105.  
[16] Blasco, J., Chen, T. M., Tapiador, J., & Peris-Lopez, P. (2016). A survey of wearable biometric recognition 
systems. ACM Computing Surveys (CSUR), 49(3), 43. 
[17] Karlen, W., Raman, S., Ansermino, J. M., & Dumont, G. A. (2013). Multiparameter respiratory rate 
estimation from the photoplethysmogram. IEEE Transactions on Biomedical Engineering, 60(7), 
1946-1953. 
[18] Download 
the 
IEEE 
TBME 
respiratory 
rate 
benchmark 
data 
set. 
Retrieved 
from 
http://www.capnobase.org/database/pulse-oximeter-ieee-tbme-benchmark  
 
Sun-Woo Lee received the B.S degree in electronic engineering from the Daejeon 
University, Korea in 2016. He is currently studying for a master’s degree in Department of 
ICT in computer software, University of Science and Technology (UST). His research 
interests are signal processing, wearable device, machine learning and embedded system. 
 
 
 
Duk-Kyun Woo received the BS, MS, and Ph.D degrees in computer science from Hongik 
University, Korea in 1993, 1995 and 2001. In 2001, he joined in the Embedded System 
Research Group at the Electronics and Telecommunications Research Institute (ETRI), Rep. 
of Korea, where he is currently a project leader and principal researcher. His research 
interests include embedded development solutions for wearable and IoT, instruction-level 
simulators, and compilers. 
 
Yong-Ki Son received the B.S and M.S. degree in electrical and electronics engineering from 
Chung-ang University, Korea in 1999, and 2001. Since 2001, he has been a principal 
researcher of Electronics and Telecommunications Research Institute (ETRI). His research 
interests include human augmentation, wearable computer and human-computer 
interaction. 
 
Pyeong-Soo Mah received the M.S and Ph.D degree in computer science and engineering 
from City University of New York, USA in 1992 and Wright State University, USA in 1995, 
respectively. Since 1996, he has been a principal researcher of Electronics and 
Telecommunications Research Institute (ETRI). His research interests include lightweight 
operating system, embedded software, and IoT systems.  
 
 
 
 
