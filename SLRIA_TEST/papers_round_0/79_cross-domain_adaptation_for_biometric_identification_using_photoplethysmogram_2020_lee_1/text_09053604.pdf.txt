CROSS-DOMAIN ADAPTATION FOR BIOMETRIC IDENTIFICATION USING
PHOTOPLETHYSMOGRAM
Eugene Lee, Annie Ho, Yi-Ting Wang, Cheng-Han Huang, Chen-Yi Lee
Institute of Electronics
National Chiao Tung University
Hsinchu, Taiwan 30010
{eugenelet.ee06g, huang50213.ee04}@nctu.edu.tw cylee@si2lab.org
ABSTRACT
The adoption of biomedical signals such as photoplethysmo-
gram (PPG) and electrocardiogram (ECG) for health parame-
ter estimation on wearable devices is growing in tandem with
the increase of attention in mobile healthcare. In our work,
we use PPG signals extracted from PPG sensors which are
used for biometric identification. A challenge for biomet-
ric identification using PPG signal is the variation in domain
(placement of sensors, wavelengths, device variation, etc.). In
this work, we propose the use of both unsupervised and semi-
supervised adversarial learning techniques for cross-domain
adaptation. As such algorithm will be deployed on wearable
devices, we propose a compact model meeting tight memory
footprint limitation. All experiments will be simulated us-
ing a public dataset (TROIKA) and our in-house dataset. By
introducing a cross-domain adaptation approach across sen-
sors, we observe an accuracy gain of 4.15% on our in-house
dataset.
The proposed semi-supervised learning technique
gives an additional accuracy boost of 2.02%.
Index Terms— Cross-domain adaptation, biometric iden-
tification, photoplethysmogram, deep learning
1. INTRODUCTION
With the increase in adoptation of wearable devices, the
widespread of using photoplethysmogram (PPG) sensors for
health parameter monitoring has become apparent. As PPG
signals extracted from the human body contains biomarkers
that is unique among different individuals, it contains im-
portant information hence it should only be accessible by
authorized parties.
In our work, we study the applicability of PPG signals
for biometric identification with the possibility of adding a
layer of security on wearable devices. We propose the us-
age of a deep neural network (DNN) as an estimation model
for biometric identification. The reasoning behind the usage
of a DNN for this task is because of its resiliency to noise
Work supported by MOST of Taiwan, project: 106-3011-E-009 -002
up to some level [1] and high adaptability to different envi-
ronments when compared with a heuristic approach. DNN
usually comes with high computational cost and has a lot pa-
rameters which does not fit into the category of wearable de-
vices. To overcome this limitation, we adopt the design Mo-
bileNetV2 [2] into our network.
Besides improving the feasibility and reliability of bio-
metric identification on wearable devices, we also study the
applicability of our algorithm when there’s a variation in PPG
sensors. As a PPG sensor consist of a photodiode and light
emitting diode (LED) manufactured with a specified spectral
sensitivity and emitting wavelength respectively, a slight vari-
ation of such device is common. To replicate such variation,
we introduce two LEDs of wavelength 850nm and 940nm
paired with photodiodes of the same type. Our approach to
this problem is to view signals from LEDs as data from dif-
ferent domains. We apply CycleGAN [3] as a cross-domain
adaptation [4, 5] method to solve this problem.
Our paper is organized as follows. We first show the cur-
rent advances in the field of biometric identification using
PPG signals and existing cross-domain adaptation methods
in Section 2. We next show our approach for cross-domain
adaptation for biometric identification in Section 3. Results
supporting the validity of our approach is shown in Section 4.
Finally, we conlcude our paper in Section 5.
2. RELATED WORK
2.1. Biometric Identification
The use of biomedical signals for biometric identification is
not novel and is an on-going research.
Most widely used
biomedical signal for biometric identification is electrocar-
diogram (ECG) signals studied by several works [6, 7]. In
our work, our focus is on PPG signals due to its pervasive
adoption in wearable devices. Earlier work like [8] uses hand-
crafted feature extractors, e.g. obtaining peak number, upward
slope, downward slope and time interval of PPG signals as
features. Using stored features as template, the identity of a
PPG signal is found by finding its nearest neighbor where eu-
1289
978-1-5090-6631-5/20/$31.00 ©2020 IEEE
ICASSP 2020
Authorized licensed use limited to: National Chiao Tung Univ.. Downloaded on May 25,2020 at 08:50:24 UTC from IEEE Xplore.  Restrictions apply. 
clidean distance is used as a metric. A follow-up work by the
authors of [8] uses fuzzy logic for decision making [9]. As the
handcrafted features obtained in the previous works wouldn’t
be consistent, a more statistical approach for feature extrac-
tion that uses linear discriminant analysis (LDA) is taken in
[10]. One main drawback of their approach is the instability
induced when the collecting condition is not controlled.
With the rise of deep learning, deep learning approaches
have also been applied to this field. In [11], different statisti-
cal features are first extracted followed by clustering method
to group different individuals and are classified using Deep
Belief Network (DBN) [12] which is pretrained using Re-
stricted Boltzmann Machine. Recently, a similar work coined
as BiometricNet [13] is proposed which uses a DNN consist-
ing of convolutional and long short-term memory (LSTM)
layers. Their work poses the biometric identification prob-
lem as a one-vs-all (binary classification) problem while our
work formulate it as a multi-class classification problem.
2.2. Cross-Domain Adaptation
The problem of cross-domain adaptation exist in multiple
research domain and is commonly applied to vision related
tasks.
One notable work is Deep Domain Confusion [14]
which is proposed for semi-supervised and unsupervised
learning.
They simultaneously optimize for both domain
invariance and classification. In their work, a domain confu-
sion loss based on maximum mean discrepancy (MMD) [15]
is adopted to calculate the domain distance. A follow-up work
[16] proposes the use of task correlation and replaces MMD
with a domain classifier to improve cross-domain adaptation.
Another notable work is CycleGAN [3] where a thorough
introduction will be given in Section 3.2.
3. METHOD
In our work, data from two domains (DA and DB) are acquired
using sensors of different wavelength placed on the finger of
the subject. Data acquired from DA and DB are denoted as
xA and xB with its corresponding identity as yA and yB re-
spectively. The number of identity (classes) is denoted as C
and is one-hot encoded.
3.1. Biometric Identification
For biometric identification using PPG signals, a deep neu-
ral network is used to model mapping from an input signal
(PPG) to the identity of an individual. The mapping func-
tion is known as a classifier denoted as C. C is designed to
be lightweight, easing the portability to wearable devices.
Our architecture is based on MobileNetV2 [2] hence we
name it PPG-MobileNet and show the architecture of C in
Table 1. Since our model deals with one-dimensional data,
all two-dimensional convolutional layers are converted to
Table 1:
Architecture of PPG-MobileNet based on Mo-
bileNetV2 [2].
Note that our architecture differs from [2]
where no bottleneck layers are repeated.
Input
Operator
t
c
s
100 × 1
conv1d
-
32
1
100 × 32
bottleneck
1
16
1
100 × 16
bottleneck
6
24
2
50 × 24
bottleneck
6
32
2
25 × 32
bottleneck
6
64
2
12 × 64
bottleneck
6
96
1
12 × 96
bottleneck
6
160
1
12 × 160
conv1d
-
512
1
1 × 512
conv1d
-
C
1
Table 2: Bottleneck residual block from [2] that transforms
c to c′ channels, with stride s, kernel size k and expansion
factor t.
Input
Operator
Output
w × c
conv1d (k = 1), ReLU
w × tc
w × tc
dwise (k = 3, s=s), ReLU
w
s × tc
w
s × tc
linear conv1d (k = 1)
w
s × c′
one-dimensional convolutional layers. This conversion also
applies to depthwise separable layers found in bottleneck
residual blocks as shown in Table 2.
The goal of our work is to apply a classifier trained using
data from DB to data from DA. The resulting classifier is
denoted as CB (subscript denotes the domain the classifier is
trained on) and this training process is illustrated in Fig. 1a.
Cross-domain inference (inference using data from DA using
classifier trained on DB) is shown in Fig. 1b.
(a) Training using data from domain
B. Red dashed line depicts the flow
of gradient.
(b) Inference using data from domain
A on model trained using data from
domain B.
Fig. 1: A classifier modeled by a deep neural network will be
used for biometric identification. (a) shows the training of the
classifier using data from domain B only. (b) uses a classifier
trained using data from domain B for the inference of data
from domain A.
3.2. Unsupervised Cross-Domain Adaptation
To translate data across domains, we adopt a one-dimensional
and simplified version of the adversarial architecture found in
1290
Authorized licensed use limited to: National Chiao Tung Univ.. Downloaded on May 25,2020 at 08:50:24 UTC from IEEE Xplore.  Restrictions apply. 
CycleGAN [3]. The role of CycleGAN is to perform unpaired
translation across domains in an unsupervised fashion. The
importance of unpaired translation for biomedical signals in
particular is the presence of phase difference between signals
if they are collected at a different time instance. An unsu-
pervised unpaired translation approach is highly suitable for
biomedical signals like PPG because of the abundance and
ease in collection of such signals.
The design of CycleGAN consists of two GANs with
an additional consistency loss. The adversarial loss [17] is
adopted for the training of GAN. Using the translation from
DA to DB as an example, we have:
LGAN(GB, DB, DA, DB) = ExB∼DB[log DB(xB)]+
ExA∼DA[log(1 − DB(GB(xA)))].
(1)
Here, the mapping function GB : DA → DB maps data across
domains and DB is a discriminator that penalties GA→B if the
domain of the translated data drifts away from the domain of
the data originating from DB.
As there are infinite mappings between domains, a cycle
consistency loss is introduced to reduce the space of possible
mapping functions. The cycle consistency loss is given as:
Lcyc(GA, GB) = ExA∼DA[||GA(GB(xA)) − xA||1]
+ ExB∼DB[||GB(GA(xB)) − xB||1].
(2)
The resulting objective is given as:
L(GA, GB, DA, DB) =LGAN(GB, DB, DA, DB)
+ LGAN(GA, DA, DB, DA)
+ λLcyc(GA, GB),
(3)
where λ corresponds to the importance of of the cycle consis-
tency loss. The learning of the generators and discriminators
is given as:
G∗
A, G∗
B = arg min
GA,GB max
DA,DBL(GA, GB, DA, DB).
(4)
An illustration summarizing the training of CycleGAN for our
application is shown in Fig. 2.
Fig. 2: Training of CycleGAN for unpaired translation of
PPG data.
To translate a PPG signal from DA to DB to be classi-
fied by CB, we used the trained GB from (4) for cross-domain
translation and feed the output of GB to CB given as:
pA = CB(GB(xA)),
(5)
and is illustrated in Figure 3.
Fig. 3: Cross-domain inference using classifier CB trained us-
ing data from DB on data translated from DA to DB using GB.
3.3. Semi-Supervised Cross Domain Adaptation
The labeling of data for biometric identification using biomed-
ical signal does not take as much effort as image labeling, e.g.
data collection can be continual for a single subject and is
dependent on the collection interval. This motivates us to
introduce partial data from DA to guide the training of GB.
To do so, we introduce a minor change on (3) where an
additional supporting loss is introduced:
Lsup(GB, DA) = −ExA,yA∼DA log pA(xA)
(6)
= −ExA,yA∼DA log CB(GB(xA)).
(7)
The supporting loss (7) can be added to (3), giving us:
L(GA, GB, DA, DB) =LGAN(GB, DB, DA, DB)
+ LGAN(GA, DA, DB, DA)
+ λLcyc(GA, GB)
+ Lsup(GB, DA).
(8)
Note that during the optimization of the new objective func-
tion (8), the parameters of CB are pretrained using DB and are
frozen as illustrated in Fig. 4. This gives us the flexibility
of swapping our generator whenever our model is deployed
on another device while a trained classifier CB can be used
directly. This has the benefit of a plug-and-play module and
prevents the problem of catastrophic forgetting on our classi-
fier.
Fig. 4: Training of generator GB is supported by gradient
backpropagated from classifier CB. The parameters of CB are
frozen during the weight update process. Red dashed line de-
picts the flow of gradient.
4. EXPERIMENTS
To show the validity of our proposed methods, we use two
datasets for simulation. The first is a public dataset known as
1291
Authorized licensed use limited to: National Chiao Tung Univ.. Downloaded on May 25,2020 at 08:50:24 UTC from IEEE Xplore.  Restrictions apply. 
TROIKA dataset [18] which consists of two-channel PPG sig-
nals collected from 12 male subjects with ages ranging from
18 to 35. Two pulse oximeters with green LEDs of wave-
length 515nm is embedded in a wristband which is used to
collect PPG signals sampled at 125 Hz. The second is our
private dataset collected using our in-house PPG sensor [19]
which has two channels of different wavelengths (850nm and
940nm). PPG signals are collected from 10 subjects aging
from 21 to 83 composed of 5 males and 5 females. PPG sig-
nal is collected from the subject’s thumb with their arm re-
laxed. A total of 8 to 11 independent sequences are collected
from each subject where a maximum of three sequences are
collected a day spanning over several days. For sequences
collected on the same day, a minimum of a 5 minutes inter-
val between collections are taken to prevent high similarity
between sequences to match the real use-case.
For training and validation set preparation for TROIKA
dataset, we randomly subsample 24% of data for validation
and the rest are used for training. Only data from the second
PPG stream is used to train our classifier. For our in-house
dataset, sequences are not joint as found in TROIKA which
matches the real use-case. We split our training and validation
data in a way where they do not originate from the same se-
quence. Approximately 30% of the sequences of each subject
is used for validation and the rest for training.
Same pre-processing steps are applied for both dataset.
We first apply a Butterworth band-pass filter of 5th order hav-
ing the cut-off frequencies of 0.1Hz - 18Hz for TROIKA and
0.01Hz - 20Hz for our in-house dataset. The band-passed fil-
ter is then de-trended (restricted to be between -1 and 1) to
ease the training of our network given as:
ˆx =
x − ¯x
max(x) − min(x).
(9)
For network training, PyTorch is used as our framework.
We use Adam optimizer at a learning rate of 0.002 and batch
size of 25 to train our classifier (both PPG-MobileNet and
BiometricNet).
For both datasets and classifiers, we train
for 250 epochs. We compare the performance of our pro-
posed architecture with BiometricNet only since Biometric-
Net is the current state-of-the-art architecture for biometric
identification using PPG. Since only binary classification is
used in BiometricNet [13], we show results for both multi-
class and binary-class classification. Comparison results are
shown in Table 3. From the results, we can see that our pro-
posed network supersedes BiometricNet in all category with
comparable model size and FLOPs as shown in Table 4. For
multi-class classification, and increment of 9.2% and 24.81%
in accuracy for our dataset and TROIKA dataset respectively
can be observed.
We next show the application of CycleGAN for both
unsupervised and semi-supervised cross-domain adaptation.
The design of CycleGAN is similar to the original paper
(using ResNet) where two-dimensional convolutional layers
Table 3: Accuracy comparison between PPG-MobileNet and
BiometricNet.
Dataset
Network
Accuracy (%)
Our Dataset
PPG-MobileNet
95.68±0.24
BiometricNet [13]
86.48±0.41
TROIKA [18]
PPG-MobileNet
89.35±1.09
(Binary-class)
BiometricNet [13]
88.81±1.35
TROIKA [18]
PPG-MobileNet
69.46±0.51
(Multi-class)
BiometricNet [13]
44.65±0.49
Table 4: Comparison of model size and computation cost.
Network
Parameters (K)
FLOPs (M)
PPG-MobileNet
343.47
41.43
BiometricNet [13]
443.34
33.48
are reduced to one-dimensional. We use PPG-MobileNet as
our classifier which attains an accuracy of 96.85% for this
experiment. Note that the classifier weights are frozen and
only the weights of CycleGAN are trained for this exper-
iment.
Convincing results are shown in Table 5 showing
a 4.15% and 6.17% accuracy gain when unsupervised and
semi-supervised adaptation are used respectively.
We can
see that there’s still room for improvement as there’s a gap
of 5.41% in accuracy when compared to directly classifying
samples from the original domain.
5. CONCLUSION
In our work, our contribution is two-fold. First, we propose a
compact architecture for biometric identification using PPG
with model size suitable for wearable devices. Second, we
propose an unsupervised and a semi-supervised cross-domain
adaptation method is applicable whenever there’s a variation
in the PPG sensor.
Using both a public and an in-house
dataset, accuracy gain is observed when compared with the
current state-of-the-art network under the same experimental
settings and network capacity. Our cross-domain adaptation
approach is also proven to be effective.
Table 5: Accuracy comparison showing importance of cross-
domain adaptation when different sensors are used.
Classifier’s Input Domain
Accuracy (%)
Original Domain
96.85
Cross-Domain w/o any Adaptation
85.27
Cross-Domain w/ Unsupervised Adaptation
89.42±0.50
Cross-Domain w/ Semi-Supervised Adaptation
91.44±0.45
1292
Authorized licensed use limited to: National Chiao Tung Univ.. Downloaded on May 25,2020 at 08:50:24 UTC from IEEE Xplore.  Restrictions apply. 
6. REFERENCES
[1] Samuel Dodge and Lina Karam, “Understanding how
image quality affects deep neural networks,” in 2016
eighth international conference on quality of multimedia
experience (QoMEX). IEEE, 2016, pp. 1–6.
[2] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey
Zhmoginov, and Liang-Chieh Chen, “Mobilenetv2: In-
verted residuals and linear bottlenecks,” in Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, 2018, pp. 4510–4520.
[3] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A
Efros,
“Unpaired image-to-image translation using
cycle-consistent adversarial networks,” in Proceedings
of the IEEE international conference on computer vi-
sion, 2017, pp. 2223–2232.
[4] Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang
Yang, and Zheng Chen, “Cross-domain sentiment clas-
sification via spectral feature alignment,” in Proceed-
ings of the 19th international conference on World wide
web. ACM, 2010, pp. 751–760.
[5] Mingsheng Long, Jianmin Wang, Guiguang Ding, Ji-
aguang Sun, and Philip S Yu, “Transfer joint matching
for unsupervised domain adaptation,”
in Proceedings
of the IEEE conference on computer vision and pattern
recognition, 2014, pp. 1410–1417.
[6] Yongjin Wang, Foteini Agrafioti, Dimitrios Hatzinakos,
and Konstantinos N Plataniotis,
“Analysis of human
electrocardiogram for biometric recognition,” EURASIP
journal on Advances in Signal Processing, vol. 2008,
no. 1, pp. 148658, 2007.
[7] Adrian DC Chan, Mohyeldin M Hamdy, Armin Badre,
and Vesal Badee, “Wavelet distance measure for person
identification using electrocardiograms,” IEEE transac-
tions on instrumentation and measurement, vol. 57, no.
2, pp. 248–253, 2008.
[8] YY Gu, Y Zhang, and YT Zhang,
“A novel biomet-
ric approach in human verification by photoplethysmo-
graphic signals,” in 4th International IEEE EMBS Spe-
cial Topic Conference on Information Technology Appli-
cations in Biomedicine, 2003. IEEE, 2003, pp. 13–14.
[9] YY Gu and YT Zhang,
“Photoplethysmographic au-
thentication through fuzzy logic,” in IEEE EMBS Asian-
Pacific Conference on Biomedical Engineering, 2003.
IEEE, 2003, pp. 136–137.
[10] Petros Spachos, Jiexin Gao, and Dimitrios Hatzinakos,
“Feasibility study of photoplethysmographic signals for
biometric identification,”
in 2011 17th International
Conference on Digital Signal Processing (DSP). IEEE,
2011, pp. 1–5.
[11] Vasu Jindal, Javad Birjandtalab, M Baran Pouyan, and
Mehrdad Nourani,
“An adaptive deep learning ap-
proach for ppg-based identification,” in 2016 38th An-
nual international conference of the IEEE engineering
in medicine and biology society (EMBC). IEEE, 2016,
pp. 6401–6404.
[12] Honglak Lee, Roger Grosse, Rajesh Ranganath, and An-
drew Y Ng, “Convolutional deep belief networks for
scalable unsupervised learning of hierarchical represen-
tations,” in Proceedings of the 26th annual international
conference on machine learning. ACM, 2009, pp. 609–
616.
[13] Luke Everson,
Dwaipayan Biswas,
Madhuri Pan-
war, Dimitrios Rodopoulos, Amit Acharyya, Chris H
Kim, Chris Van Hoof, Mario Konijnenburg, and Nick
Van Helleputte,
“Biometricnet: Deep learning based
biometric identification using wrist-worn ppg,” in 2018
IEEE International Symposium on Circuits and Systems
(ISCAS). IEEE, 2018, pp. 1–5.
[14] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko,
and Trevor Darrell,
“Deep domain confusion: Max-
imizing for domain invariance,”
arXiv preprint
arXiv:1412.3474, 2014.
[15] Karsten M Borgwardt, Arthur Gretton, Malte J Rasch,
Hans-Peter Kriegel, Bernhard Sch¨olkopf, and Alex J
Smola, “Integrating structured biological data by ker-
nel maximum mean discrepancy,” Bioinformatics, vol.
22, no. 14, pp. e49–e57, 2006.
[16] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate
Saenko,
“Simultaneous deep transfer across domains
and tasks,” in Proceedings of the IEEE International
Conference on Computer Vision, 2015, pp. 4068–4076.
[17] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio, “Generative adversar-
ial nets,” in Advances in neural information processing
systems, 2014, pp. 2672–2680.
[18] Zhilin Zhang, Zhouyue Pi, and Benyuan Liu, “Troika:
A general framework for heart rate monitoring using
wrist-type photoplethysmographic signals during inten-
sive physical exercise,” IEEE Transactions on biomedi-
cal engineering, vol. 62, no. 2, pp. 522–531, 2014.
[19] Eugene Lee, Tsu-Jui Hsu, and Chen-Yi Lee, “Central-
ized state sensing using sensor array on wearable de-
vice,” in 2019 IEEE International Symposium on Cir-
cuits and Systems (ISCAS). IEEE, 2019, pp. 1–5.
1293
Authorized licensed use limited to: National Chiao Tung Univ.. Downloaded on May 25,2020 at 08:50:24 UTC from IEEE Xplore.  Restrictions apply. 
